# config/config.yaml

# Configuration pour le scraper Minima
mode: "scrap" 


# Liste d’URLs à traiter
urls:
  - https://fr.wikipedia.org/wiki/France
  - https://fr.wikipedia.org/wiki/Allemagne
  - https://fr.wikipedia.org/wiki/Burkina_Faso

# Paramètres réseau
timeout: 10
retries: 3
delay: 0.5

# Paramètres HTTP
headers:
  User-Agent: "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"
  Accept: "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8"
  Accept-Language: "fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7"
  Accept-Encoding: "gzip, deflate"
  Connection: "keep-alive"
  Upgrade-Insecure-Requests: "1"
  Referer: "https://www.google.com/"



# Mode parallèle
parallel: true
max_workers: 5  # nombre maximal de threads simultanés

# Export
export_prefix: "results"

# Journalisation
log_level: "INFO"
log_format: "[%(asctime)s] [%(levelname)s] %(message)s"
