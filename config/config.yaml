# config/config.yaml


# Mode d’exécution : "scrap", "crawl", "scrap+crawl"
mode: "crawl"
max_depth: 2  # pour le crawl
max_links_per_page: 10  # pour le crawl


# Mode parallèle
parallel: true
max_workers: 5  # nombre maximal de threads simultanés

queue_flush_every: 5  # vider la file d’attente après ce nombre de pages traitées
export_flush_every: 10  # exporter les résultats après ce nombre de pages traitées

accepted_languages:
  - en
  - fr
  

# Liste d’URLs à traiter
urls:
 - "https://www.lefaso.net"
  
# Paramètres réseau
timeout: 10
retries: 3
delay: 0.5

# Paramètres HTTP
headers:
  User-Agent: "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"
  Accept: "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8"
  Accept-Language: "fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7"
  Accept-Encoding: "gzip, deflate"
  Connection: "keep-alive"
  Upgrade-Insecure-Requests: "1"
  Referer: "https://www.google.com/"


# Export
export_prefix: "results"

# Journalisation
log_level: "INFO"
log_format: "[%(asctime)s] [%(levelname)s] %(message)s"
